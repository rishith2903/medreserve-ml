# ğŸ§  MedReserve â€” ML Service (Flask)

See overall architecture diagram: [../../docs/architecture.mmd](../../docs/architecture.mmd)

REST API that provides:
- Patient â†’ specialization recommendations
- Doctor â†’ diagnosis and medicine suggestions

Runs on http://localhost:5001 by default.

## ğŸš€ Quickstart

OS-specific quick reference: see the root README section â€œOS-specific instructionsâ€.
```
cd backend/ml
pip install -r requirements.txt
python api/ml_api.py
```

Health: GET http://localhost:5001/health

## ğŸ“¡ Endpoints (JSON)
- POST /predict/specialization
  - { "symptoms": "chest pain and shortness of breath", "top_k": 3 }
- POST /predict/diagnosis
  - { "symptoms": "...", "top_diseases": 5, "top_medicines": 5 }
- POST /predict/batch/specialization
- POST /predict/batch/diagnosis
- GET /models/info

## ğŸ”§ Configuration (.env example â€” no secrets)
```
PORT=5001
DEBUG=false
```

## ğŸ§ª Testing
```
pytest -q
# Smoke
curl http://localhost:5001/health
```

## ğŸ³ Docker (service-only)
```
docker build -t medreserve-ml .
docker run -p 5001:5001 medreserve-ml
```

Tip: Prefer running all services with a root docker-compose (ask me to create it).

## ğŸŒ Production
- Example ML URL: https://medreserve-ml.onrender.com (update if different)

## ğŸ”’ Notes
- Input is validated; avoid sending PII
- Use HTTPS in production
